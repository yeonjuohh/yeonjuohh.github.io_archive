{
    "componentChunkName": "component---src-templates-blog-post-js",
    "path": "/isl/ch8/",
    "result": {"data":{"site":{"siteMetadata":{"title":"Hado Log"}},"markdownRemark":{"id":"933e28ff-3082-5bfb-921e-710084f69e28","excerpt":"Tree 모델들은 X를 여러 개의 공간으로 나누고, 새로운 관측치가 속하는 범위의 데이터의 평균 등을 사용해 예측을 한다. X를 나누는 규칙이 tree 형태로 요약될 수 있기 때문에, decision tree 방법이라고 한다. Tree…","html":"<ul>\n<li>Tree 모델들은 <em>X</em>를 여러 개의 공간으로 나누고, 새로운 관측치가 속하는 범위의 데이터의 평균 등을 사용해 예측을 한다. <em>X</em>를 나누는 규칙이 tree 형태로 요약될 수 있기 때문에, decision tree 방법이라고 한다.</li>\n<li>Tree 모델은 해석하기에는 용이하지만 다른 모델들에 비해 예측력이 뛰어나지 않는다. 그렇기 때문에 여러 개의 tree를 만들어 하나의 결과를 내는 bagging, random forests, boosting등의 방법이 같이 쓰이기도 한다.</li>\n</ul>\n<h2>8.1 The Basics of Decision Trees</h2>\n<ul>\n<li>Decision tree는 regression과 classification 문제에서 모두 사용할 수 있다.</li>\n</ul>\n<h3>8.1.1 Regression Trees</h3>\n<p><strong>Predicting Baseball Players’ Salaries Using Regression Trees</strong></p>\n<ul>\n<li>야구선수의 연봉을 예측하고 싶다고 하자. 문제에서 주어진 변수로는 메이저 리그에서 활동한 시간, 전년도 타율이 있다.</li>\n<li>이 데이터에 decision tree를 적용한다면, 가장 먼저 모델은 데이터를 메이저 리그에서 활동한 시간이 4.5년 미만인 그룹, 이상이 그룹으로 나눈다. 그리고, 활동 시간이 4.5년 이상인 그룹은 다시 전년도 타율에 따라 세 그룹으로 나뉘게 된다. 결론적으로 <em>X</em>는 4개의 그룹으로 나뉘게 되는데, 이를 terminal nodes 또는 leaves라 한다.</li>\n<li>모델링 결과를 해석해 보면, 메이저 리그에서 활동한 시간이 연봉 예측에 가장 중요한 변수이다. 메이저 리그에서 4.5년 이상 선수 생활을 했다면 전년도 타율이 연봉에 영향을 미치는데 타율이 높을수록 연봉은 높다.</li>\n</ul>\n<p><strong>Prediction via Stratification of the Feature Space</strong></p>\n<ul>\n<li>그렇다면 decision tree는 어떻게 만드는 걸까? 간단하게 말하자면 다음과 같다.\n<ol>\n<li><em>X</em>를 J개의 독립적인 범위, <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>R</mi><mn>1</mn></msub><mo separator=\"true\">,</mo><mi mathvariant=\"normal\">.</mi><mi mathvariant=\"normal\">.</mi><mi mathvariant=\"normal\">.</mi><mo separator=\"true\">,</mo><msub><mi>R</mi><mi>j</mi></msub></mrow><annotation encoding=\"application/x-tex\">R_{1}, ..., R_{j}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.969438em;vertical-align:-0.286108em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.00773em;\">R</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.00773em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\">...</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.00773em;\">R</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.311664em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.00773em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.05724em;\">j</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span></span></span></span></span>로 나눈다.</li>\n<li><span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>R</mi><mi>j</mi></msub></mrow><annotation encoding=\"application/x-tex\">R_{j}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.969438em;vertical-align:-0.286108em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.00773em;\">R</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.311664em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.00773em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.05724em;\">j</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span></span></span></span></span> 범위에 속하는 모든 관측치에 대해서, <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>R</mi><mi>j</mi></msub></mrow><annotation encoding=\"application/x-tex\">R_{j}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.969438em;vertical-align:-0.286108em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.00773em;\">R</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.311664em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.00773em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.05724em;\">j</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span></span></span></span></span>  데이터의 평균을 예측치로 한다.</li>\n</ol>\n</li>\n<li>RSS를 최소화하는 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>R</mi><mn>1</mn></msub><mo separator=\"true\">,</mo><mi mathvariant=\"normal\">.</mi><mi mathvariant=\"normal\">.</mi><mi mathvariant=\"normal\">.</mi><mo separator=\"true\">,</mo><msub><mi>R</mi><mi>j</mi></msub></mrow><annotation encoding=\"application/x-tex\">R_{1}, ..., R_{j}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.969438em;vertical-align:-0.286108em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.00773em;\">R</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.00773em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\">...</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.00773em;\">R</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.311664em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.00773em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.05724em;\">j</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span></span></span></span></span>를 찾는 게 가장 좋지만, 계산량이 너무 많기 때문에 대신 top-down, greedy 방법인 recursive binary splitting을 사용한다. 나무의 꼭대기에서 시작하기 때문에 top-down, 분기점마다 두 개의 그룹으로 나누기 때문에 binary, final RSS를 고려하지 않고 각 단계에서 RSS를 최소화하는 방법을 찾기 때문에 greedy하다.</li>\n<li><em>X</em>를 나누는 과정은 중단 조건을 만족할 때까지 계속한다. 예를 들어, 모든 node에 데이터 수가 5개 이하면 멈춘다.</li>\n</ul>\n<p><strong>Tree Pruning</strong></p>\n<ul>\n<li>앞에서 살펴본 방법으로 모델링을 하다 보면 overfitting의 문제점이 생길 가능성이 크다.</li>\n<li>이를 해결할 수 있는 방법 중 하나는 RSS의 감소가 어느 정도 이상일 때까지만 tree를 키우는 것이다. 하지만, RSS를 크게 감소시키는 split이 나중에 오는 데이터에서는 효과적인 방법이 아니다.</li>\n<li>대신 일단 매우 큰 tree를 만들고, pruning을 해서 subtree를 얻는 게 더 좋은 방법이 될 수 있다.</li>\n<li>그렇다면 test erro가 가장 작은 subtree을 어떻게 얻을 수 있을까? 모든 subtree에 대해 cross-validation 방법을 쓰는 건 계산량이 너무 많아질 수 있기 때문에 cost complexitiy pruning 방법을 제안한다.</li>\n<li>Cost complexity pruning 방법을 사용하려면 pruing 변수 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>α</mi></mrow><annotation encoding=\"application/x-tex\">\\alpha</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.0037em;\">α</span></span></span></span></span>만 cross-validation 등의 방법으로 정하면 된다. <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>α</mi></mrow><annotation encoding=\"application/x-tex\">\\alpha</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.0037em;\">α</span></span></span></span></span>가 0이면 원래의 매우 큰 tree이고, 최댓값인 1에 가까이 갈수록 tree는 pruning 된다. 이 방법은 lasso의 원리와 비슷하다고 할 수 있다.</li>\n</ul>\n<h2>8.1.2 Classification Trees</h2>\n<ul>\n<li>Classification tree는 qualitative인 Y를 예측하는 데 사용된다는 것을 제외하고 regression tree와 매우 유사하다.</li>\n<li>Regression tree에서는 데이터가 속하는 terminal node 데이터의 평균값을 예측치로 사용했다. Classification에서는 데이터가 속하는 terminal node 데이터들의 class 중 가장 빈도수가 높은 값을 예측치로 사용한다. 또한, 단순히 예측값뿐만 아니라 class 비율도 결과를 해석하는데 중요한 요소 중 하나이다.</li>\n<li>Recursive binary splitting 방법으로 tree를 만드는데, RSS를 계산하기 어렵기 때문에 대신 classification error rate을 사용한다.</li>\n<li>하지만, classification error rate만을 사용하는 건 tree를 계속 키워갈 때 충분하지 않는 경우가 많다. 그렇기 때문에 Gini index와 cross-entropy가 추가로 사용된다.</li>\n<li>Gini index는 class들의 총 분산을 수치화한 지표이다. Node의 purity를 측정하는 지표라고도 불리며, 값이 작을수록 각 node에 한 개의 class가 지배하고 있다는 걸 의미한다. Cross-entropy도 Gini index와 비슷한 특징을 가지고 있어, node가 순수할수록 값이 작아진다.</li>\n<li>새로운 node를 만들 때, classification error rate 보다는 Gini index 또는 cross-entropy가 node purity에 더 민감하기 때문에 세 지표가 보통 같이 쓰인다. 하지만, 모델링의 목적이 단순히 예측력이라면 classification error rate만 사용하는 게 선호된다.</li>\n<li>Tree를 만들다 보면 두 개 이상의 terminal node에서 예측값이 같은 경우가 있는데, 이는 classification error rate 보다 Gini index 또는 cross-entropy 값을 낮추기 위함이다.</li>\n</ul>\n<h3>8.1.3 Tree Versus Linear Models</h3>\n<ul>\n<li>Linear과 tree 중 예측력이 더 좋은 모델은 데이터에 따라 다르다. 만약, <em>X</em>와 <em>Y</em>가 선형 관계라면 linear 모델이, 두 변수가 비선형 또는 복잡한 관계라면 tree 모델을 사용하는 게 좋다. 그리고 예측력은 cross-validation 또는 validation set 방법으로 구한 test error로 비교할 수 있다.</li>\n<li>문제에서 예측이 주요 목적이 아니라면, tree 모델이 해석 및 시각화가 더 쉽기 때문에 선호될 수 있다.</li>\n</ul>\n<h3>8.1.4 Advantages and Disadvantages of Trees</h3>\n<ul>\n<li>Decision tree의 장점은 다음과 같다.\n<ul>\n<li>사람들에게 설명하기에 쉽다.</li>\n<li>몇몇 사람들은 decision tree가 사람의 의사결정 과정과 유사하다고 생각한다.</li>\n<li>시각화가 쉽다.</li>\n<li>질적 변수를 dummpy 변수로 변환하지 않고 사용가능하다.</li>\n</ul>\n</li>\n<li>하지만, decision tree는 지금까지 배운 모델들에 비해 예측력이 떨어진다는 단점이 있다.</li>\n</ul>\n<h2>8.2 Bagging, Random Forests, Boosting</h2>\n<ul>\n<li>Bagging, Random Forests, Boosting은 tree들을 이용해 예측력이 더 좋은 모델을 만든다.</li>\n</ul>\n<h3>8.2.1 Bagging</h3>\n<ul>\n<li>Decision tree는 분산이 높다는 단점이 있다. 이는 데이터를 어떻게 train과 test로 나누는지에 따라 모델의 결과가 많이 달라질 수 있다는 의미이다.</li>\n<li>관측치를 평균 내면 분산은 감소한다. 이를 statistical learning에 적용하면, 여러 개의 train 데이터로 만든 모델에서 예측한 값의 평균값을 구하면 된다.</li>\n<li>하지만, 많은 경우 우리에게는 제한된 데이터만 주어지기 때문에 bootstrap 방법을 사용한다. 즉, train 데이터에서 랜덤으로 여러 번 데이터를 추출하는 것이다. 그리고 각 샘플에서 구한 예측값의 평균을 사용하면 된다. 이를 baggin이라 한다. Bagging은 특히 decision tree에 적용했을 때 유용하다.</li>\n<li>Classification 문제에서는 예측 결과로 가장 많이 나온 class 값을 사용하면 된다.</li>\n<li>샘플을 많이 뽑는다고 overfitting 문제가 생기지 않는다. 보통 test error가 안정화되는 정도만큼 샘플을 만든다.</li>\n</ul>\n<p><strong>Out-of-Bag Error Estimation</strong></p>\n<ul>\n<li>평균적으로 하나의 bagged tree는 전체 데이터의 2/3을 사용한다. 모델에 사용되지 않는 관측치는 out-of-bag이라고 한다.</li>\n<li>Out-of-bag 관측치 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>x</mi><mi>i</mi></msub></mrow><annotation encoding=\"application/x-tex\">x_{i}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span></span>가 있다고 하자. <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>x</mi><mi>i</mi></msub></mrow><annotation encoding=\"application/x-tex\">x_{i}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span></span>의 test error는 본인이 포함되어 있지 않은 샘플로 만든 3개의 모델에서 얻은 예측치의 평균으로 구할 수 있다. 그리고 이 방법을 모든 데이터에 적용하면 out-of-bag MSE 또는 classification error를 얻게 된다.</li>\n<li>샘플을 충분히 많이 뽑는다면, out-of-bag 오류는 leave-one-out cross-validation 오류에 근사한다.</li>\n<li>데이터 수가 많아 cross-validation의 계산량이 많은 문제에서는 out-of-bag error를 대신 사용하기도 한다.</li>\n</ul>\n<p><strong>Variable Importance Measures</strong></p>\n<ul>\n<li>Bagging 방법을 사용하면 모델의 예측치는 좋아지지만 decision tree의 장점인 해석 가능성이 없어진다.</li>\n<li>하지만, RSS 또는 Gini index를 사용해 변수의 중요도를 수치화할 수 있다. Bagging으로 구한 각각의 tree에서 특정 변수로 splitting을 한 후 RSS 또는 Gini index의 감소량의 평균을 구한다. 이 값이 클수록 중요한 변수라고 생각할 수 있다.</li>\n</ul>\n<h3>8.2.2 Random Forests</h3>\n<ul>\n<li>Random forest는 tree들의 연관성을 줄여 bagging 보다 예측력이 더 좋은 모델을 만드는 방법이다.</li>\n<li>Bagging에서와 같이, bootstraped 샘플로 decision tree를 만든다. Bagging과 다른 점은 전체 변수가 아닌 랜덤으로 선택한 m개의 변수를 이용해 splitting을 한다는 것이다. Splitting을 할 때마다 m개의 변수를 새로 뽑아야 하며, 보통 전체 변수 수에서 루트를 취한 값만큼 뽑는다.</li>\n<li>예를 들어, 데이터에서 한 변수가 <em>Y</em>를 예측하는데 아주 중요하다고 하자. 그렇다면 아무리 많은 bagged tree를 만들어도 tree의 윗 부분에서 이 변수가 사용되어 모든 모델에서의 결과가 비슷할 것이다. 즉, 상관관계가 높다. 상관관계가 높으면 평균을 구하더라도 분산은 줄어들지 않는다.</li>\n<li>반면 random forest는 모든 변수를 고려하지 않기 때문에 어떤 모델에서는 이 중요한 변수가 아예 사용되지 않을 수 있고, 이는 tree간의 상관관계를 낮춘다.</li>\n<li>변수끼리 상관관계가 높다면 작은 m값을 사용하는게 좋을 수 있다.</li>\n</ul>\n<h3>8.2.3 Boosting</h3>\n<ul>\n<li>\n<p>Boosting은 bagging처럼 decision tree뿐만 아니라 다른 모델에서도 사용 가능한 방법이다.</p>\n</li>\n<li>\n<p>Bagging은 독립적인 샘플 데이터로 tree를 만드는 방법이라고 한다면, boosting은 전 모델에서 얻은 정보를 이용해 계속 모델을 만든다.</p>\n<ol>\n<li>\n<p>데이터의 모든 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>i</mi></mrow><annotation encoding=\"application/x-tex\">i</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.65952em;vertical-align:0em;\"></span><span class=\"mord mathnormal\">i</span></span></span></span></span>에 대해 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mover accent=\"true\"><mi>f</mi><mo>^</mo></mover><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo><mo>=</mo><mn>0</mn><mo separator=\"true\">,</mo><msub><mi>r</mi><mi>i</mi></msub><mo>=</mo><msub><mi>y</mi><mi>i</mi></msub></mrow><annotation encoding=\"application/x-tex\">\\hat{f}(x)=0, r_{i}=y_{i}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.2078799999999998em;vertical-align:-0.25em;\"></span><span class=\"mord accent\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9578799999999998em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10764em;\">f</span></span><span style=\"top:-3.26344em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.08332999999999999em;\"><span class=\"mord\">^</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.19444em;\"><span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">x</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.8388800000000001em;vertical-align:-0.19444em;\"></span><span class=\"mord\">0</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">r</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">y</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span></span>라고 하자.</p>\n</li>\n<li>\n<p><span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>b</mi><mo>=</mo><mn>1</mn><mo separator=\"true\">,</mo><mn>2</mn><mo separator=\"true\">,</mo><mi mathvariant=\"normal\">.</mi><mi mathvariant=\"normal\">.</mi><mi mathvariant=\"normal\">.</mi><mo separator=\"true\">,</mo><mi>B</mi></mrow><annotation encoding=\"application/x-tex\">b=1, 2, ..., B</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"mord mathnormal\">b</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.8777699999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord\">1</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\">2</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\">...</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.05017em;\">B</span></span></span></span></span>에 대해 다음을 반복한다.</p>\n<p>(a) D번 split하는 tree <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msup><mover accent=\"true\"><mi>f</mi><mo>^</mo></mover><mi>b</mi></msup></mrow><annotation encoding=\"application/x-tex\">\\hat{f}^{b}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.1523199999999998em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord accent\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9578799999999998em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10764em;\">f</span></span><span style=\"top:-3.26344em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.08332999999999999em;\"><span class=\"mord\">^</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.19444em;\"><span></span></span></span></span></span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.849108em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">b</span></span></span></span></span></span></span></span></span></span></span></span></span>를 만든다.</p>\n<p>(b) (a)에서 구한 tree로 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mover accent=\"true\"><mi>f</mi><mo>^</mo></mover></mrow><annotation encoding=\"application/x-tex\">\\hat{f}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.1523199999999998em;vertical-align:-0.19444em;\"></span><span class=\"mord accent\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9578799999999998em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10764em;\">f</span></span><span style=\"top:-3.26344em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.08332999999999999em;\"><span class=\"mord\">^</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.19444em;\"><span></span></span></span></span></span></span></span></span></span>를 업데이트한다.</p>\n<div class=\"math math-display\"><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mover accent=\"true\"><mi>f</mi><mo>^</mo></mover><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo><mo>=</mo><mover accent=\"true\"><mi>f</mi><mo>^</mo></mover><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo><mo>+</mo><mi>λ</mi><msup><mover accent=\"true\"><mi>f</mi><mo>^</mo></mover><mi>b</mi></msup><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">\\hat{f}(x)=\\hat{f}(x)+\\lambda\\hat{f}^{b}(x)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.2078799999999998em;vertical-align:-0.25em;\"></span><span class=\"mord accent\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9578799999999998em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10764em;\">f</span></span><span style=\"top:-3.26344em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.08332999999999999em;\"><span class=\"mord\">^</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.19444em;\"><span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">x</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.2078799999999998em;vertical-align:-0.25em;\"></span><span class=\"mord accent\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9578799999999998em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10764em;\">f</span></span><span style=\"top:-3.26344em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.08332999999999999em;\"><span class=\"mord\">^</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.19444em;\"><span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">x</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.2078799999999998em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\">λ</span><span class=\"mord\"><span class=\"mord accent\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9578799999999998em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10764em;\">f</span></span><span style=\"top:-3.26344em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.08332999999999999em;\"><span class=\"mord\">^</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.19444em;\"><span></span></span></span></span></span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8991079999999999em;\"><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">b</span></span></span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">x</span><span class=\"mclose\">)</span></span></span></span></span></div>\n<p>(c) 잔차를 업데이트한다.</p>\n<div class=\"math math-display\"><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><msub><mi>r</mi><mi>i</mi></msub><mo>=</mo><msub><mi>r</mi><mi>i</mi></msub><mo>−</mo><mi>λ</mi><msup><mover accent=\"true\"><mi>f</mi><mo>^</mo></mover><mi>b</mi></msup><mo stretchy=\"false\">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">r_{i}=r_{i}-\\lambda\\hat{f}^{b}(x_{i})</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">r</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.73333em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">r</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.2078799999999998em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\">λ</span><span class=\"mord\"><span class=\"mord accent\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9578799999999998em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10764em;\">f</span></span><span style=\"top:-3.26344em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.08332999999999999em;\"><span class=\"mord\">^</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.19444em;\"><span></span></span></span></span></span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8991079999999999em;\"><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">b</span></span></span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span></span></div>\n</li>\n<li>\n<p>예측치를 구한다.</p>\n</li>\n</ol>\n<div class=\"math math-display\"><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mover accent=\"true\"><mi>f</mi><mo>^</mo></mover><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo><mo>=</mo><msubsup><mi mathvariant=\"normal\">Σ</mi><mrow><mi>b</mi><mo>=</mo><mn>1</mn></mrow><mi>B</mi></msubsup><mi>λ</mi><msup><mover accent=\"true\"><mi>f</mi><mo>^</mo></mover><mi>b</mi></msup><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">\\hat{f}(x)=\\Sigma^{B}_{b=1}\\lambda\\hat{f}^{b}(x)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.2078799999999998em;vertical-align:-0.25em;\"></span><span class=\"mord accent\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9578799999999998em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10764em;\">f</span></span><span style=\"top:-3.26344em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.08332999999999999em;\"><span class=\"mord\">^</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.19444em;\"><span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">x</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.2078799999999998em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord\">Σ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8913309999999999em;\"><span style=\"top:-2.4530000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">b</span><span class=\"mrel mtight\">=</span><span class=\"mord mtight\">1</span></span></span></span><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.05017em;\">B</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.247em;\"><span></span></span></span></span></span></span><span class=\"mord mathnormal\">λ</span><span class=\"mord\"><span class=\"mord accent\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9578799999999998em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10764em;\">f</span></span><span style=\"top:-3.26344em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.08332999999999999em;\"><span class=\"mord\">^</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.19444em;\"><span></span></span></span></span></span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8991079999999999em;\"><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">b</span></span></span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">x</span><span class=\"mclose\">)</span></span></span></span></span></div>\n</li>\n<li>\n<p>쉽게 설명하면 boosting은 전 모델로 얻은 잔차를 <em>Y</em>로 하는 모델을 계속 만드는데, 이렇게 만들어지는 tree는 보통 작다. 잔차에 계속 tree를 만들게 되면 모델의 예측력이 떨어지는 부분을 천천히 개선할 수 있다. <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>λ</mi></mrow><annotation encoding=\"application/x-tex\">\\lambda</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"mord mathnormal\">λ</span></span></span></span></span> 값이 클수록 속도는 더 느려진다.</p>\n</li>\n<li>\n<p>Bagging과 달리 boosting으로 만들어지는 각 tree는 전 tree들의 모양에 영향을 받는다.</p>\n</li>\n<li>\n<p>Bootsting에서는 결정해야 하는 3개의 변수가 있다.</p>\n<ul>\n<li>Tree의 개수 B이다. Bagging, random forest와 달리 boosting에서는 B가 너무 크면 overfitting 될 수 있다. 보통 cross-validation으로 값을 정한다.</li>\n<li>Boosting이 데이터를 배우는 속도를 조절하는 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>λ</mi></mrow><annotation encoding=\"application/x-tex\">\\lambda</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"mord mathnormal\">λ</span></span></span></span></span>이다. 문제마다 다른데 보통 0.01 또는 0.001 값을 사용한다. 많은 문제에서 B는 크게 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>λ</mi></mrow><annotation encoding=\"application/x-tex\">\\lambda</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"mord mathnormal\">λ</span></span></span></span></span>는 작게하면 좋은 결과를 얻을 수 있다.</li>\n<li>각 tree에서 split을 얼마나 할지 결정하는 d이다. 보통 d=1일 때 결과가 좋다. 그리고 d가 1의 값을 가지면 additive model처럼 생각 할 수 있어 해석 가능성이 높아진다.</li>\n</ul>\n</li>\n</ul>","frontmatter":{"title":"Ch 8. Tree-Based Methods","date":"January 15, 2022","description":"Introduction to Statistical Learning Chapter 8 Notes","category":null,"tags":["ISL"]}},"previous":{"fields":{"slug":"/isl/ch7/"},"frontmatter":{"title":"Ch 7. Moving Beyond Linearity"}},"next":null},"pageContext":{"id":"933e28ff-3082-5bfb-921e-710084f69e28","previousPostId":"07aac5d5-4d7b-57e1-a25c-5f5bca53ae39","nextPostId":null}},
    "staticQueryHashes": ["2841359383"]}